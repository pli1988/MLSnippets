{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network with Tensorflow\n",
    "\n",
    "CNN on MNIST. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (60000, 28, 28, 1)\n",
      "y train:  (60000, 10)\n",
      "x test:  (10000, 28, 28, 1)\n",
      "y test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# rescale x to be in [0,1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[:,:,:,None]\n",
    "x_test = x_test[:,:,:,None]\n",
    "\n",
    "# categorical encoding for y\n",
    "n_classes = 10\n",
    "\n",
    "y_train_cat = np.zeros([len(y_train), n_classes])\n",
    "y_train_cat[range(len(y_train)),y_train]= 1\n",
    "\n",
    "\n",
    "y_test_cat = np.zeros([len(y_test), n_classes])\n",
    "y_test_cat[range(len(y_test)),y_test]= 1\n",
    "\n",
    "\n",
    "print('x train: ', x_train.shape)\n",
    "print('y train: ', y_train_cat.shape)\n",
    "\n",
    "\n",
    "print('x test: ', x_test.shape)\n",
    "print('y test: ', y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Util.util import Model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    \n",
    "    def __init__(self, cnn_dims, mlp_dims, input_dim, n_classes):\n",
    "        \n",
    "        self.cnn_dims = cnn_dims\n",
    "        self.mlp_dims = mlp_dims\n",
    "        \n",
    "        self.x = tf.placeholder(name = 'input',\n",
    "                                shape = (None, input_dim, input_dim, 1),\n",
    "                                dtype = tf.float32)\n",
    "        \n",
    "        self.ground_truth = tf.placeholder(name = 'ground_truth',\n",
    "                                           shape = (None, n_classes),\n",
    "                                           dtype = tf.float32)   \n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "                \n",
    "    def build_forward(self):\n",
    "        '''Build forward pass'''\n",
    "        \n",
    "        # CNN\n",
    "        \n",
    "        for i, cnn_dim in enumerate(self.cnn_dims):\n",
    "            \n",
    "            if i == 0:\n",
    "                y = tf.layers.Conv2D(cnn_dim, 3, activation=tf.nn.relu)(self.x)\n",
    "            else:\n",
    "                y = tf.layers.Conv2D(cnn_dim, 3, activation=tf.nn.relu)(y)\n",
    "            \n",
    "            y = tf.layers.max_pooling2d(y, pool_size=2, strides=1)\n",
    "        \n",
    "        y = tf.layers.flatten(y)\n",
    "        \n",
    "        #MLP\n",
    "        for i, dim in enumerate(self.mlp_dims):\n",
    "\n",
    "                y = y = tf.layers.Dense(units = dim, activation=tf.nn.relu)(y)\n",
    "\n",
    "        # logits here since loss performs softmax for numerical reasons\n",
    "        self.logits = tf.layers.Dense(n_classes, activation=None)(y)\n",
    "\n",
    "        \n",
    "    def build_train(self):\n",
    "        \n",
    "        # cross-entropy\n",
    "        self.loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=self.ground_truth, logits=self.logits))\n",
    "        \n",
    "        # minimize loss with Adam\n",
    "        self.train_step = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        \n",
    "    def build_aux(self):\n",
    "        \n",
    "        # predicted probabilities\n",
    "        _probs = tf.nn.softmax(self.logits)\n",
    " \n",
    "        # predicted class (arg max)\n",
    "        self.pred = tf.argmax(_probs, axis = 1)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n",
      "Epoch 1   Train Acuracy 0.854\n",
      "Epoch 2   Train Acuracy 0.912\n",
      "Epoch 3   Train Acuracy 0.914\n",
      "Epoch 4   Train Acuracy 0.932\n",
      "Epoch 5   Train Acuracy 0.942\n",
      "Epoch 6   Train Acuracy 0.95\n",
      "Epoch 7   Train Acuracy 0.946\n",
      "Epoch 8   Train Acuracy 0.924\n",
      "Epoch 9   Train Acuracy 0.958\n",
      "Epoch 10   Train Acuracy 0.96\n",
      "Epoch 11   Train Acuracy 0.95\n",
      "Epoch 12   Train Acuracy 0.956\n",
      "Epoch 13   Train Acuracy 0.958\n",
      "Epoch 14   Train Acuracy 0.952\n",
      "Epoch 15   Train Acuracy 0.956\n",
      "Epoch 16   Train Acuracy 0.956\n",
      "Epoch 17   Train Acuracy 0.956\n",
      "Epoch 18   Train Acuracy 0.956\n",
      "Epoch 19   Train Acuracy 0.956\n"
     ]
    }
   ],
   "source": [
    "m = CNN(cnn_dims = [16,16, 8], mlp_dims=[64,64], input_dim=28, n_classes=10)\n",
    "loss_val = m.train(x_train, y_train_cat, num_epoch=20, batch_size=64, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_val)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('steps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = m.predict(x_test)\n",
    "acc = accuracy(y_test, y_test_pred)\n",
    "\n",
    "print('Test Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
